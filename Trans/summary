可以做这样的总结：
传统的word2vec和transformer结构在embedding层的异同：
不同点：
1、word2vec是静态的，训练完成之后不会优化，属于无监督学习，而embedding层和后续模型一起训练，是动态的，并且通过transformer结构的自注意力机制，可以实现一词多义，而word2vec仅能实现一词一义
2、传统的word2vec，是先训练词嵌入矩阵，再训练模型，两者是分开操作的；而transformer模型是将embedding层和模型放在一起训练的
3、传统的word2vec是先将输入单词进行one-hot编码，然后再通过降维的方式将每个单词变成可训练的向量，而transformer结构中的embedding层是通过查表的方式获取对应的可训练向量
相同点
1、在经过训练之后，词嵌入矩阵或者tranformer结构中embedding层训练的表，都可以表示词语之间的相关性
2、词嵌入矩阵的参数和transformer结构中embedding层表的参数是一致的，都是最大单词数*降维之后的维度数


关于自注意力机制：Q可以理解为当前词，K可以理解为上下文词，V可以理解为输入，Q和K的点乘用于计算当前词和上下文词之间的相关性


对于自注意力机制，我有这样子的理解，有这样两句话，第一句话是：我喜欢炒股，因为炒股可以赚钱；第二句话是，炒股是一件有风险的事情；经过Q和K的计算之后，对于第一句话，炒股和赚钱的关联性更强，应该在结果矩阵中相关性更好，而在第二句话中，炒股和风险关联性更强，在结果矩阵中相关性更好；最终再和V进行计算，第一句话的计算结果，炒股和赚钱，被点亮更多；而在第二句话中，炒股和风险被点亮更多

自注意力机制和跨注意力机制：
Q、K、V均来源于输入，在自注意力机制中，GPT模型
Q和K有不同的来源，在跨注意力机制中

为什么需要建立Q和K两个矩阵，为什么不能共用矩阵？
因为在自然语言中，需要考虑上下文之间的非对称依赖关系，比如说，炒股可以赚钱这句话，"炒股" 对 "赚钱" 的依赖 ≠ "赚钱" 对 "炒股" 的依赖；
如果Q和K使用的是同一个矩阵的话，经过矩阵计算，炒股*依赖 == 依赖*炒股，无法体现两者之间的依赖关系
而如果Q和K使用不同的矩阵，那么经过计算，Q当前词和K上下文词被映射到了不同的空间，再计算炒股*依赖 ！= 依赖*炒股，可以体现上下文的非对称依赖关系
我突然有个疑问，对于上面那个解释，如果正确的话，当前词 炒股，和上下文词赚钱，炒股在经过Q的计算之后，赚钱在经过K的计算之后，分别映射到了不同的空间，如果这个transformer结构经过充分的学习，那么即使分别映射到了不同的空间，那么他们之间的相关性也会越来越强


对于transformer结构中的位置编码和为什么要有Q和K两个矩阵，我分别有如下理解：
为什么要有位置编码：
如果没有位置编码的话，经过embedding的计算，不包含位置信息，例如：“狗咬人”中的”狗“和”人“等于”人咬狗“中的”狗“和”人“，但是增加了位置编码之后，这两个句子中的”人“和”狗“就不一样了，包含了位置信息，更方便后续学习，可以让transformer结构更加好区分”狗咬人“和“人咬狗”的关系
为什么要有Q和K两个矩阵：
因为需要非对称的上下文依赖关系
在“狗咬人”这个句子中，如果Q和K是同一个矩阵的话，那么狗 -> 人等于人 -> 狗，但是实际这是不一样的，有了Q和K这两个矩阵之后，网络结构就可以区分出来狗 -> 人 和 人 -> 狗的区别，构建了出来上下文依赖关系，所以需要Q和K两个矩阵
总结一下：位置编码是为了获取两个相似（也可以说对称）句子的区别，Q和K需要两个不同的矩阵是为了获取一个句子中的上下文依赖关系


学习总结：
1、多头注意力机制为什么Q和K的矩阵维度是(n_module,n_module)，有四点：
第一点：如果是(n_module, n_size)模型入参增加，增大调优难度；
第二点，相同维度的矩阵，有助于发挥计算优势；
第三点：主流实现都这么用
第四点：Transformer 的残差连接要求输入输出维度一致，保持 n_module，避免额外线性学习
2、自注意力机制中的Q映射关系的作用：
降低维度，保留关键信息
基本假设，单词之间的关系，知会在关键几个维度中出现；
Q映射进行降低维度，强迫网络将注意力放在关键的维度上，对不关键维度进行忽略；
多头的降维是通过分头隐式完成的
这个思想和PCA思想类似，都是通过降低维度，关注关键部分，忽略不重要部分；
自注意力机制中的Q和PCA的区别在于：
PCA是静态的，被动的，Q是主动的，可学习的
PCA的目标函数是最大化投影方差（无监督），Q是最小化任务损失（有监督）
PCA依赖全局数据，Q对于局部数据进行适配
PCA是去除低方差方向，Q是通过梯度下降学习过滤和任务无关的特征
PCA的降维是线性的，Q的降维，因为后面的softmax，包含了一些非线性成分
3、多头注意力机制
目的：将一个词映射到不同的空间，在不同空间下学习和其他词之间的关联
为什么单头不行：若只有一个头，模型必须将所有类型的关系（语法、语义、位置等）压缩到同一组投影中，容易导致语义混淆，并且可能会导致不同语义的优化方向冲突
多头数量的选择：取决于词向量的维度，词向向量越大，头应该越多；因为更大的词向量，涵盖了更多的语义，更多的任务，更长的上下文依赖，如果头不足，不利于对词的不同含义进行区分；一般保持dk ~=64-128
相较于RNN的优势：RNN无法理解一词多义，而transformer可以
4、自注意力机制和多头注意力机制功能上的区别：
自注意力机制的作用在于建立双向非对称的依赖关系，并且是动态的
多头注意力机制的作用在于多视角关系建模；这里有一个注意点，一个视角下，关注一种关系，但是不代表不存在其他关系，其他关系依旧存在，但是被弱化，被关注的关系被增强；
多头注意力机制还有两个要点：动态性和注意力矩阵的稀疏性；
动态性是指，针对同一句子，因为不同的Q*Kt（每个头的Q和K矩阵独立），可以针对同一个词，构建不同的依赖关系；eg：“炒股可以赚钱，但是有风险”，假设有两个头，一个头可以构建炒股 -> 赚钱的关系，一个头可以构建炒股 -> 风险的关系，在两个头不同的Q*Kt注意力权重矩阵中，一个在炒股 -> 赚钱的值更大，一个在炒股 -> 风险的值更大；
稀疏性指的是，经过学习（损失函数迫使不同头分工）和softmax（softmax的竞争机制，指数运算放大最大值）优化，不同的头在Q*Kt这个注意力权重矩阵中，一种依赖关系会更突出（数值更大），其他依赖关系会变弱（数值趋近于0），例如一个头经过多轮学习和优化，构建炒股 -> 赚钱的注意力权重值越来越大，炒股 -> 风险注意力权重值趋近于0；另一个头的情况则反之
5、自注意力机制的动态性和多头注意力机制的动态性：
自注意力机制下的动态性，对于同一个词，在不同句子中，经过Q*Kt注意力权重矩阵的计算，可以对不同的词构建依赖关系
eg：”炒股可以赚钱“和”炒股有风险“这两句话中的炒股，在经过Q*Kt注意力权重矩阵计算之后，一个构建的是炒股 -> 赚钱，一个构建的是炒股 -> 风险”；炒股一词，在不同的语境下对不同的词构建更强的依赖关系，这就是自注意力机制下的动态性
多头注意力机制下的动态性，对于同一个词，经过不同头的Q*Kt计算，在不同头下，对不同的词构建更强的依赖关系：
eg：“炒股可以赚钱，但是炒股有风险”这句话中的炒股，假设有两个头，一个头中构建的关系是炒股 -> 赚钱，一个头是炒股 -> 风险，也就是在不同的头下，同一个词，经过不同的Q*Kt注意力权重矩阵的计算，对不同词构建不同的依赖关系（对应位置的数值更大）
多头动态性相较于单头动态性的优势在于（还有注意力矩阵的稀疏性），对于一个很长，很复杂的句子，eg：“炒股可以赚钱，但是有风险，因此需要学习，并且时刻关注宏观政策，企业运行状况以及大盘走势”这个句子中，炒股 -> 赚钱、风险、政策、大盘、企业都有关系，如果只在一个头下构建关系，会存在关系混淆和梯度优化方向冲突的问题，但是分在不同的投下，则可以避免这个问题



关于dropout层和mask层，我做如下总结：
1、dropout层的作用是为了防止过拟合和对某一部分特别依赖，因此选择在神经网络训练过程中，将一部分数据丢弃（置为0）的操作
dropout层只在训练过程中使用，在推理和预测过程中不会使用
2、mask层，mask层是用于控制神经网络中，哪些部分应该被处理，哪些部分应该被忽略的作用；在transformer结构中，主要用在两个方面
第一 paddingMask，作用是为了防止padding出来的单词对依赖矩阵计算的影响；由于实际句子长短不一，有些句子长度可能只有80，但是对于一个输入长度为100的transformer结构，80之后的部分需要padding为0，经过Q和K注意力权重矩阵计算之后，padding为0的部分还对之前的部分构建了依赖关系，实际上这是不符合实际的，因此在计算注意力权重矩阵的softmax的时候，会将padding部分对之前部分的注意力权重在计算softmax的时候置为负无穷；
第二sequenceMask，作用是控制注意力权重矩阵的可视范围（可选），在注意力权重矩阵中(i, j)位置的值的含义是第i个词对第j个词的依赖关系（空间距离），如果i大于j，那么就是后面的词对前面词的依赖关系，如果i小于j，那么就是前面的词对后面词的依赖关系，对于GPT模型，模型是只能先看前面的内容，再看到后面的内容，因此在训练的过程中，不应该构建前面词对后面词的依赖关系，这不符合实际。所以，在编码器中，不使用sequence_mask，对内容进行全面理解，但是在解码器中，需要使用mask，防止解码器作弊
还有一个区别就在于，mask是在训练和推理的过程中都使用，dropout只在训练的时候使用
还有就是，mask主要作用在注意力权重矩阵，也就是Q*Kt计算softmax的过程，而dropout是作用在多头注意力机制的全连接层