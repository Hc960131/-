可以做这样的总结：
传统的word2vec和transformer结构在embedding层的异同：
不同点：
1、word2vec是静态的，训练完成之后不会优化，属于无监督学习，而embedding层和后续模型一起训练，是动态的，并且通过transformer结构的自注意力机制，可以实现一词多义，而word2vec仅能实现一词一义
2、传统的word2vec，是先训练词嵌入矩阵，再训练模型，两者是分开操作的；而transformer模型是将embedding层和模型放在一起训练的
3、传统的word2vec是先将输入单词进行one-hot编码，然后再通过降维的方式将每个单词变成可训练的向量，而transformer结构中的embedding层是通过查表的方式获取对应的可训练向量
相同点
1、在经过训练之后，词嵌入矩阵或者tranformer结构中embedding层训练的表，都可以表示词语之间的相关性
2、词嵌入矩阵的参数和transformer结构中embedding层表的参数是一致的，都是最大单词数*降维之后的维度数


关于自注意力机制：Q可以理解为当前词，K可以理解为上下文词，V可以理解为输入，Q和K的点乘用于计算当前词和上下文词之间的相关性


对于自注意力机制，我有这样子的理解，有这样两句话，第一句话是：我喜欢炒股，因为炒股可以赚钱；第二句话是，炒股是一件有风险的事情；经过Q和K的计算之后，对于第一句话，炒股和赚钱的关联性更强，应该在结果矩阵中相关性更好，而在第二句话中，炒股和风险关联性更强，在结果矩阵中相关性更好；最终再和V进行计算，第一句话的计算结果，炒股和赚钱，被点亮更多；而在第二句话中，炒股和风险被点亮更多

自注意力机制和跨注意力机制：
Q、K、V均来源于输入，在自注意力机制中，GPT模型
Q和K有不同的来源，在跨注意力机制中

为什么需要建立Q和K两个矩阵，为什么不能共用矩阵？
因为在自然语言中，需要考虑上下文之间的非对称依赖关系，比如说，炒股可以赚钱这句话，"炒股" 对 "赚钱" 的依赖 ≠ "赚钱" 对 "炒股" 的依赖；
如果Q和K使用的是同一个矩阵的话，经过矩阵计算，炒股*依赖 == 依赖*炒股，无法体现两者之间的依赖关系
而如果Q和K使用不同的矩阵，那么经过计算，Q当前词和K上下文词被映射到了不同的空间，再计算炒股*依赖 ！= 依赖*炒股，可以体现上下文的非对称依赖关系
我突然有个疑问，对于上面那个解释，如果正确的话，当前词 炒股，和上下文词赚钱，炒股在经过Q的计算之后，赚钱在经过K的计算之后，分别映射到了不同的空间，如果这个transformer结构经过充分的学习，那么即使分别映射到了不同的空间，那么他们之间的相关性也会越来越强